---
title: Generate Handwritten Digits Using GAN
author: Akshara Soman
date: 07-12-2024
date-modified: last-modified
image: gan_arch.png
toc: true
categories:
  - project
  - gen-ai
  - GAN
  - pytorch
---

### Objective of the Project

Build a DC-GAN (Deep Convolutional Generative Adversarial Network) to generate images of handwritten digits.

### Important Details

1.  Dataset: MNIST handwritten digits dataset (grayscale)
2.  Model: Generative Adversarial Network (GAN)
3.  Code available at: <https://github.com/aksharasoman/dcgan>
4.  It can be built in google colab: [python-notebook](https://github.com/aksharasoman/dcgan/blob/f245b0250f79fcba497506f58dd080faeceade71/GAN_handwrittenDigits.ipynb)

### Overview

A Generative Adversarial Network (GAN) model has two major components: a generator and a discriminator. @fig-gan-arch gives outline of a GAN model.

![Basic GAN architecture](gan_arch.png){#fig-gan-arch width="60%"}

A generator creates fake samples that mimic the real samples provided to the discriminator network. The discriminator is a binary classifier that evaluates these inputs, determining whether each one is real or fake. The generator's objective is to produce fake samples that are so similar to real ones that the discriminator incorrectly identifies them as genuine.

GAN loss function consists of two parts: generator loss and discriminator loss.

::: {.callout-note appearance="simple"}
### GAN Training Strategy
During generator training, the discriminator's weights are kept constant and are not updated, and vice versa.
:::

### Implementation

This project can be divided into 7 tasks.

1.  Configurations
2.  Load dataset
3.  Load dataset into batches
4.  Create discriminator network
5.  Create generator network
6.  Create loss function & optimizer
7.  Training Loop

For ease of understanding, you may refer to the [iPython notebook](https://github.com/aksharasoman/dcgan/blob/f245b0250f79fcba497506f58dd080faeceade71/GAN_handwrittenDigits.ipynb), where each task is coded in separate sections.

::: {.callout-tip collapse="true"}
### Expected learnings

1.  What is Generative Adversarial Network
2.  [Applications of GANs](ApplicationsGANs.qmd)(Current state-of-art performers for these applications)
3.  What is Generator?
4.  What is discriminator?
5.  Understanding architecture
6.  Loss functions
7.  How to generate a fake image using GAN?
8.  How to download and transform data in Pytorch?
9.  How to calculate input image size for each layer?
10. How to build a GAN model from scratch in pytorch?
11. How to train a Generative Adversarial Network?
    1.  How to train the model on colab with GPU?
    2.  How to train the model in a remote cluster environment?
12. Challenges in GAN
:::

### Results Snapshot
::: {layout-ncol=2}
![Digits generated after the first epoch](generated_digits_epoch1.png){.lightbox fig-align="left"}

![Digits generated after 15 epochs](generated_digits_epoch15.png){.lightbox fig-align="left"}
:::


### References
1.  Coursera Guided Project: "[Deep Learning with PyTorch : Generative Adversarial Network](https://www.coursera.org/projects/deep-learning-with-pytorch-generative-adversarial-network#details)"

::: {.callout-tip collapse="true"}
### Further Readings
1. A good intro blog with details of related problems: [link](https://pyimagesearch.com/2021/09/13/intro-to-generative-adversarial-networks-gans/)
2. [How can generative adversarial networks learn real-life distributions easily - Microsoft Research](https://www.microsoft.com/en-us/research/blog/how-can-generative-adversarial-networks-learn-real-life-distributions-easily/) 
3. [Understanding Failure Modes of GAN Training | by Kartik Chaudhary | Medium](https://medium.com/game-of-bits/understanding-failure-modes-of-gan-training-eae62dbcf1dd)
4. [DCGAN Paper](https://arxiv.org/pdf/1511.06434v2) 
:::

::: {.callout-tip collapse="true"}
### Possible Extensions
1. Generate fashion cloth images (Dataset: FashionMNIST - grayscale)
	1. Extend it to color images ([ref](https://pyimagesearch.com/2021/12/13/gan-training-challenges-dcgan-for-color-images/))
2. Text to image 
:::